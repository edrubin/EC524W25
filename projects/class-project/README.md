# Class project

## Project description

**Topic** Select a prediction-related topic and "register" it with me (Ed).

- The topic should be related to something we talked about it class, but it cannot be something we directly covered. The idea is to extend our course topics to new applications/areas.
- You should have a motivation for why this topic is interesting/important.
- You should also have a good example of an application of this topic.
- **Still important** People cannot overlap in topics. First mover wins.

## Materials due

Your topic is due by the end of the day on **February 9th**.

By 11:59p on **March 12th**, submit **two documents** on Canvas (share links or upload files):

1. an HTML notebook of the Wiki explanation of your topic that includes the intuition, math, and example (including code)
1. slides for a five-minute presentation explaining the topic and showing your example 

**NOTE:** No late submissions.

## Claimed topics

**Day 1 Presentations** Thursday, 13 March 2025, 10a–11:20a

| Topic | Name |
|:---------|:---------|
| *Maximum likelihood estimation* | Natalie Mathers |
| *Neural nets* | Ocea Roberts Thompson |
| *Adversarial learning* | Andre Fulton |
| *Reinforcement learning* | Isaac Wilfong |
| *Transfer learning* | Michelle Ohwobete |
| *Time-series with recurrent and time-delayed neural nets* | Hunter Wright |
| *Convolutions* | Darian Miranda Olivas |
| *Image processing* | Miles Jew |
| *Bayesian neural networks* | Jane Morgan |
| *MCMC in prediction* | Sebastian Jaramillo Diaz |
| *Natural language processing (NLP)* | Wenbo Teng |
| *Large language models (LLMs)* | Shi Zhang Ooi |

**Day 2 Presentations** Friday, 14 March 2025, 2p–2:50p

| Topic | Name |
|:---------|:---------|
| *Het. trt. effects with S- and T-learners* | Sanam Haddadian |
| *Double-debiased ML* | Tom Ben-Shahar |
| *Causal forests* | Mira Cross |
| *Fraud/anomaly detection* | Yulisa Lopez Jeronimo |
| *Clustering algorithms* | Setareh Shiralian |
| *Discriminant analysis* | Jack Schlosser |
| *LightGBM and Catboost (esp. with imbalance)* | Woojin Kim |

## Some ideas for topics

You are not limited to these ideas, but here are some suggestions:

- Multi-level output (esp. ordered)
- Maximum likelihood estimation
- Discriminant analysis
- Bayesian machine learning methods
- Relaxing IID assumptions
	- Clustering
	- Time-series prediction (esp. CV)
	- Spatial prediction (esp. CV)
- Image processing (e.g., facial recognition or satellite imagery)
- Natural Language Processing (NLP)
- Transfer learning (esp. [Hugging Face](https://huggingface.co/))
- Neural networks
- Convolutions
- Reinforcement learning
- Adversarial learning
- Unsupervised learning (esp. clustering algorithms)
- Semi-supervised learning
- Graphical methods
- Experiments
- Heterogeneous treatment effect estimation
- Extensions on standard "boosting"
